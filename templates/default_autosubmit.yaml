# Default Autosubmit Error Catalog Template
# This template is used by: as-scan <expid>
#
# This catalog uses dynamic variable extraction to automatically discover:
#   - SSH username from ~/.ssh/config
#   - Experiment ID from remote Autosubmit configuration
#   - Platform/host information from remote configuration
#   - Base paths from remote Autosubmit installation
#
# Variables can be extracted from any fsspec-compatible source:
#   - Local files: ~/.ssh/config
#   - Remote SSH: sftp://climatedt-wf/path/to/config.yml
#   - S3: s3://bucket/path/to/config.yml
#   - GitHub: github://org:repo@ref/path/to/config.yml
version: 1.0.0
schema_version: 1.0.0
metadata:
  name: "Autosubmit Scan"
  description: "Default error catalog for Autosubmit experiments with dynamic configuration"
  author: "autosubmit-scan"
  created: "2024-01-01T00:00:00+00:00"
  updated: "2024-01-01T00:00:00+00:00"
  # Dynamic variable extraction
  # Variables are extracted in order and can reference each other
  variables:
    # Extract experiment ID from environment variable or CLI argument
    # This would be set by the CLI when running: as-scan <expid>
    expid:
      source: "env"
      pattern: "AUTOSUBMIT_EXPID"
      default: "a2sg"
    # Extract HPC username from experiment metadata
    # Can be overridden with: export AUTOSUBMIT_HPCUSER=myusername
    hpc_user:
      source: "file"
      path: "sftp://climatedt-wf/appl/AS/AUTOSUBMIT_DATA/{{ expid }}/conf/metadata/experiment_data.yml"
      method: "yaml_path"
      pattern: "HPCUSER"
      default: "unknown"
    # Extract remote HPC host from experiment metadata
    hpc_host:
      source: "file"
      path: "sftp://climatedt-wf/appl/AS/AUTOSUBMIT_DATA/{{ expid }}/conf/metadata/experiment_data.yml"
      method: "yaml_path"
      pattern: "HPCHOST"
      default: "unknown"
    # Extract platform short name from experiment metadata
    platform_name:
      source: "file"
      path: "sftp://climatedt-wf/appl/AS/AUTOSUBMIT_DATA/{{ expid }}/conf/metadata/experiment_data.yml"
      method: "yaml_path"
      pattern: "HPCHPCARCH_SHORT"
      default: "unknown"
    # Extract HPC log directory from experiment metadata
    hpc_log_dir:
      source: "file"
      path: "sftp://climatedt-wf/appl/AS/AUTOSUBMIT_DATA/{{ expid }}/conf/metadata/experiment_data.yml"
      method: "yaml_path"
      pattern: "HPCLOGDIR"
      default: "/tmp/LOG_{{ expid }}"
errors:
  # Critical Errors - Job Failures
  SlurmOutOfMemory:
    id: SlurmOutOfMemory
    pattern:
      type: regex
      pattern: 'slurmstepd.*error.*Exceeded.*memory|oom-kill|Out of memory|Killed.*memory'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Job exceeded allocated memory and was killed by SLURM on platform: {{ platform_name }}"
    suggestion: "Increase memory allocation in job configuration"
    context_lines: 10
    next_errors: []
    metadata:
      severity: critical
      category: resource
  SlurmTimeLimit:
    id: SlurmTimeLimit
    pattern:
      type: regex
      pattern: 'TIME LIMIT|DUE TO TIME LIMIT|TIMEOUT|slurmstepd.*error.*time limit'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Job exceeded allocated walltime and was terminated on platform: {{ platform_name }}"
    suggestion: "Increase walltime allocation or optimize job performance"
    context_lines: 10
    next_errors: []
    metadata:
      severity: critical
      category: resource
  SlurmNodeFailure:
    id: SlurmNodeFailure
    pattern:
      type: regex
      pattern: 'NODE FAILURE|node.*fail|SLURM_ERROR|launch failed|unable to launch'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "SLURM node failure or job launch problem on platform: {{ platform_name }}"
    suggestion: "Check node status and resubmit job. May be transient hardware issue."
    context_lines: 10
    next_errors: []
    metadata:
      severity: critical
      category: infrastructure
  # Python Errors
  PythonTraceback:
    id: PythonTraceback
    pattern:
      type: regex
      pattern: 'Traceback \(most recent call last\)|^\s*File .*, line [0-9]+'
      flags: ["MULTILINE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Python exception occurred during execution"
    suggestion: "Review Python traceback for specific error and fix code"
    context_lines: 15
    next_errors:
      - error_id: PythonImportError
        when:
          type: field_contains
          field: matched_text
          value: "ImportError"
      - error_id: PythonKeyError
        when:
          type: field_contains
          field: matched_text
          value: "KeyError"
    metadata:
      severity: high
      category: code
  PythonImportError:
    id: PythonImportError
    pattern:
      type: regex
      pattern: 'ImportError|ModuleNotFoundError|No module named'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Python module import failed"
    suggestion: "Check Python environment and install missing dependencies"
    context_lines: 10
    next_errors: []
    metadata:
      severity: high
      category: environment
  PythonKeyError:
    id: PythonKeyError
    pattern:
      type: literal
      pattern: "KeyError"
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Dictionary key access error in Python code"
    suggestion: "Check data structure and key names in code"
    context_lines: 10
    next_errors: []
    metadata:
      severity: medium
      category: code
  # NetCDF/Data Errors
  NetCDFError:
    id: NetCDFError
    pattern:
      type: regex
      pattern: 'NetCDF.*error|nc_open.*failed|Invalid.*netcdf'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "NetCDF file operation failed"
    suggestion: "Check NetCDF file exists, is readable, and not corrupted"
    context_lines: 10
    next_errors: []
    metadata:
      severity: high
      category: data
  MissingInputFile:
    id: MissingInputFile
    pattern:
      type: regex
      pattern: 'No such file|File not found|cannot open.*No such file|FileNotFoundError'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Required input file is missing"
    suggestion: "Check file paths and ensure all input files exist"
    context_lines: 10
    next_errors: []
    metadata:
      severity: critical
      category: data
  # Fortran/Model Errors
  FortranRuntimeError:
    id: FortranRuntimeError
    pattern:
      type: regex
      pattern: 'Fortran runtime error|forrtl.*error|SIGSEGV|segmentation fault'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "Fortran model runtime error or segmentation fault"
    suggestion: "Check model configuration, input data, and memory settings"
    context_lines: 15
    next_errors: []
    metadata:
      severity: critical
      category: model
  MPIError:
    id: MPIError
    pattern:
      type: regex
      pattern: 'MPI.*error|mpi_abort|MPI_ERR|Fatal error in PMPI'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
    meaning: "MPI communication or initialization error"
    suggestion: "Check MPI configuration, node communication, and process counts"
    context_lines: 15
    next_errors: []
    metadata:
      severity: critical
      category: infrastructure
  # General Errors
  ErrorKeyword:
    id: ErrorKeyword
    pattern:
      type: regex
      pattern: '\bERROR\b|\bFATAL\b|\bCRITICAL\b'
      flags: ["IGNORECASE"]
    files:
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.out"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/**/*.err"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/../rundir/**/ifs.*"
      - "sftp://{{ hpc_user }}@{{ hpc_host }}{{ hpc_log_dir }}/../rundir/**/NODE.*"
    meaning: "Generic error keyword found in logs"
    suggestion: "Review error message for specific issue"
    context_lines: 5
    next_errors: []
    metadata:
      severity: medium
      category: general
